{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned up version of makemore MLP implementation (for V1 - look at MLP notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading our data\n",
    "words = open(r'dataset\\names.txt',mode='r').read().splitlines()\n",
    "words[:10]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'} \n",
      " 27\n"
     ]
    }
   ],
   "source": [
    "#charset\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "S_to_I = {s:i+1 for i,s in enumerate(chars)}\n",
    "S_to_I['.'] = 0\n",
    "I_to_S = {i:s for s,i in S_to_I.items()}\n",
    "vocab_size  = len(I_to_S)\n",
    "\n",
    "print(I_to_S,'\\n', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "def build_dataset(words):\n",
    "    X, Y = [],[]\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w +'.':\n",
    "            ix = S_to_I[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(I_to_S[i] for i in context), '----->', I_to_S[ix])\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X,Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 *len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "X_train, y_train = build_dataset(words[n1:])\n",
    "X_valid, y_valid = build_dataset(words[n1:n2])\n",
    "X_test , y_test = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters (outside of functional code block for easier interpretability and maintenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_emb = 10 #Number of dimensions for character embeddings\n",
    "n_hidden = 300 #Number of neurons in our Hidden tanh layer\n",
    "g =  torch.Generator().manual_seed(2147483647) # Set seed for reproducability\n",
    "C = torch.randn([vocab_size,n_emb], generator=g) #Our embedding table\n",
    "w1 = torch.randn([(n_emb* block_size),n_hidden],    generator=g) / (5/3)/(((n_emb*block_size)**0.5)) #*0.2 #created weights1 init to randn tensor with shape ( from our embedding, and 100 outputs as per our hyperparameter)\n",
    "b1 = torch.randn((n_hidden),    generator=g) * 0.01\n",
    "w2 = torch.randn([n_hidden,vocab_size],     generator=g) * 0.01 #created weights2 init to randn tensor with shape (100 as outputs from prev layer tanh, and 27 outputs as per our 'possible' charset)\n",
    "b2 = torch.randn((vocab_size),  generator=g) * 0 #At init, we set our b2 to zero, so we do not influence our logits and have a more even dist in the logits to record a lower init loss.\n",
    "\n",
    "#BatchNorm Parameters\n",
    "bN_gain = torch.ones((1,n_hidden)) #Batch Norm gain applied to scale and shift normalized batch, and allow network to backprop and adjust weights to move the normalized batch accordingly.\n",
    "bN_bias = torch.zeros((1,n_hidden)) #Batch Norm bias applied to similarly to Batch Norm gain above.\n",
    "bNmean_running = torch.zeros((1,n_hidden)) #bNmean running init to zero, as per our gaussian distribution.\n",
    "bNstd_running = torch.ones((1,n_hidden)) #bNstd running init to one, as per our gaussian distribution.\n",
    "#-------------------\n",
    "\n",
    "params = [C, w1, b1, w2, b2, bN_gain, bN_bias] #created new params variable to hold all Parameters as a list, so we can calculate total parameters in our network\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18297 parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'{sum(p.nelement() for p in params)} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 100000: 3.3112\n",
      "  10000/ 100000: 2.0707\n",
      "  20000/ 100000: 1.8647\n",
      "  30000/ 100000: 2.1928\n",
      "  40000/ 100000: 1.9839\n",
      "  50000/ 100000: 2.3732\n",
      "  60000/ 100000: 1.8674\n",
      "  70000/ 100000: 1.7613\n",
      "  80000/ 100000: 1.8196\n",
      "  90000/ 100000: 2.0648\n",
      "1.7736772298812866\n"
     ]
    }
   ],
   "source": [
    "step_size = 100000\n",
    "batch_size = 64\n",
    "loss_acq = []\n",
    "for i in range(step_size):\n",
    "    #Minibatch from dataset\n",
    "    ix = torch.randint(0,X_train.shape[0], (batch_size, ),    generator=g) \n",
    "    Xtr, Ytr = X_train[ix], y_train[ix]\n",
    "    \n",
    "    #Forward pass\n",
    "    emb = C[Xtr] #Embedding vector\n",
    "    embcat = emb.view(emb.shape[0],-1) #Joined embedding to have same number of dimensions as w1 for matrix muliplication\n",
    "    h_preact = (embcat @ w1) #+ b1 # ---Side note, no need to have bias when using BatchNorm, esp BatchNorm in place with training, as bias is controlled by the BatchNorm bias\n",
    "    bNmean_i = h_preact.mean(0,keepdim=True) #BatchNorm mean at i iteration in the training\n",
    "    bNstd_i = h_preact.std(0, keepdim=True) #BatchNorm std at i iteration in the training\n",
    "    \n",
    "    h_preact_bN = bN_gain * (h_preact - bNmean_i )/bNstd_i + bN_bias #BatchNormalization layer, added before hidden tanh/activation layer, - added bNmean_i and bNstd_i for bNmean & bNstd calibration.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        bNmean_running = 0.99 * bNmean_i + 0.001 * bNmean_running\n",
    "        bNstd_running = 0.99 * bNstd_i + 0.001 * bNstd_running\n",
    "    \n",
    "    h = torch.tanh(h_preact_bN)\n",
    "    logits = h @ w2 +b2\n",
    "    #counts = logits.exp()\n",
    "    #prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "    #loss = -prob[torch.arange(16),Y].log().mean()\n",
    "    loss = F.cross_entropy(logits, Ytr)\n",
    "    \n",
    "    #Backward pass\n",
    "    for p in params:\n",
    "        p.grad =None\n",
    "    loss.backward()\n",
    "    #learning rate adjust\n",
    "    #lr = learn_step[i]\n",
    "    #Update\n",
    "    lr= 0.1 if i < 50000 else 0.01\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad\n",
    "    #learning rate tracking\n",
    "    #learn_used.append(learn_exp[i])\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i:7d}/{step_size:7d}: {loss.item():.4f}')\n",
    "    loss_acq.append(loss.log10().item())\n",
    "    break\n",
    "        \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10))\n",
    "#plt.imshow(h.abs() > 0.99, cmap='grey', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(h.view(-1).tolist(),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_acq);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that calibration below can be done in running with the network training iteration - Only kept in here as note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate the bN mean & std at the end of training\n",
    "with torch.no_grad():\n",
    "    emb = C[X_train]\n",
    "    embcat = emb.view(emb.shape[0],-1)\n",
    "    h_preact = embcat @ w1 + b1\n",
    "#measure/calc the mean & std over the entire training set\n",
    "    bN_mean = h_preact.mean(0,keepdim=True)\n",
    "    bN_std = h_preact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Validation split loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.2584645748138428\n",
      "valid loss: 3.2588956356048584\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (X_train, y_train),\n",
    "        'valid': (X_valid, y_valid),\n",
    "        'test': (X_test, y_test)\n",
    "    }[split]\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0],-1)\n",
    "    h_preact = (embcat @ w1) + b1\n",
    "    h_preact_bN = bN_gain * (h_preact - bNmean_running)/ bNstd_running + bN_bias\n",
    "    h = torch.tanh(h_preact_bN)\n",
    "    logits = h @ w2 +b2\n",
    "    #counts = logits.exp()\n",
    "    #prob = counts / counts.sum(dim=1, keepdim=True)\n",
    "    #loss = -prob[torch.arange(16),Y].log().mean()\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split,'loss:', loss.item())\n",
    "    \n",
    "split_loss('train')\n",
    "split_loss('valid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grabetzmaton.\n",
      "xegh.\n",
      "quriffryne.\n",
      "whegvinggupfred.\n",
      "kylynnnsh.\n",
      "gdwfploddp.\n",
      "xvvedhmen.\n",
      "doxqing.\n",
      "ktexgenfxwer.\n",
      "qujfatton.\n",
      "fawguguffuddh.\n",
      "wwy.\n",
      "wyxpi.\n",
      "xfmpseus.\n",
      "xhe.\n",
      "cubabkumwnnvyfferonquyphioshfrdev.\n",
      "juwafguchanvonguss.\n",
      "chragriq.\n",
      "blyk.\n",
      "grychiamberly.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])]\n",
    "        embcat = emb.view(emb.shape[0],-1)\n",
    "        h = torch.tanh((embcat @ w1) + b1)\n",
    "        logits = h @ w2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(I_to_S[i] for i in out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchfied Summary code of BatchNorm and Activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378897 parameters\n",
      "      0/ 100000: 3.2983\n",
      "  10000/ 100000: 2.2153\n",
      "  20000/ 100000: 2.0614\n",
      "  30000/ 100000: 1.8009\n",
      "  40000/ 100000: 1.7688\n",
      "  50000/ 100000: 1.7286\n",
      "  60000/ 100000: 1.7739\n",
      "  70000/ 100000: 1.6999\n",
      "  80000/ 100000: 1.8644\n",
      "  90000/ 100000: 1.7052\n",
      "1.8589887619018555\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True): #This is us initializing our linear layer ( Weight * input + bias) (Note we init our weight and bias, and our function takes fan_in & fan_out as args (input and output features))\n",
    "        self.weight = torch.randn(fan_in, fan_out, generator=g) / fan_in**0.5 #fan_in is just input features (in our code it is the number of embeddings*block size)(self.weight == w1 in our code above)\n",
    "        self.bias = torch.zeros(fan_out) if bias else None #self-explanatory, it is the bias init to zeros\n",
    "    \n",
    "    def __call__(self,x): #Here we define what should happen when we call our linear layer\n",
    "        self.out = x @ self.weight #Matrix multiplcation as above our logits_preact layer (h_preact above)\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias #Here we set condition to add bias to our matrix multiplication product is bias is not None (0)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self): #Here we define what happens with our parameters (Weight & Bias)\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias]) #Return a list of our weights and a list of our biases\n",
    "    \n",
    "class BatchNorm1d: #Our BatchNorm Layer\n",
    "    def __init__(self, dim , eps = 1e-5, momentum=0.1): #Initializing of our batch norm layer, that takes dim, eps, momentum as args, dim is the shape/size of input our activation layer will take\n",
    "        self.eps = eps\n",
    "        self.momentum  = momentum\n",
    "        self.training = True   #This lets our function know that we are currently training our model, hence set to true, False would be otherwise.\n",
    "        \n",
    "        self.gamma = torch.zeros(dim) #gamma is our BatchNorm bias, similar to our bN_bias in the code above\n",
    "        self.beta = torch.ones(dim) #beta is BatchNorm gain, simliar to our bN_gain in code above\n",
    "        \n",
    "        self.running_mean = torch.zeros(dim) #The running mean of the batch norm function, calculated in place with the batchNorm to avoid a stage 2 computation of this stat, similar to code above\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self,x): #definig what happens when we call our BatchNorm layer (class)\n",
    "        if self.training: #When in training, the following is executed\n",
    "            xmean = x.mean(0, keepdims=True) #We  calculate the mean along columns (axis 0) going down, for arg x that our function takes. The shape of this mean tensor would be 1, dim of x (the batch), the mean of the batch\n",
    "            xvar = x.var(0, keepdim=True) #Similar to the mean calculation above, however now we caulcate the variance, the variance of the batch\n",
    "        else: #Following code is executed if we are not training the model\n",
    "            xmean = self.running_mean #The mean of the batch is set to the running mean\n",
    "            xvar = self.running_var #Similarly the variance of the batch is set to the running variance\n",
    "        xhat = (x- xmean)/torch.sqrt(xvar+self.eps) #Normalization, ensuring the batch has a unit gaussian and 0 mean\n",
    "        self.out = self.gamma + self.beta + xhat #Adding the gain and bias to our batch\n",
    "        if self.training: #This code will be executed if the model is set to training\n",
    "            with torch.no_grad(): #Decorator to alert Pytorch not to compute the gradients for these, as we will not backprop on them\n",
    "                self.running_mean = ((1-self.momentum) * self.running_mean) + (self.momentum * xmean) #The running mean is updated with majority of what it was (0.9*r mean) and nudged (0.1) in the direction of the current mean\n",
    "                self.running_var = ((1-self.momentum) * self.running_var) + (self.momentum * xvar) #Similar to the running mean update\n",
    "        return self.out #Returns the output of our batch with the gain and bias\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "class Tanh: #Our activation layer/class\n",
    "    def __call__(self, x): #Our call function which takes our batch as an arg\n",
    "        self.out = torch.tanh(x) #Applies torch.tanh to our batch and stores it as output\n",
    "        return self.out #function returns the output when completed\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "\n",
    "n_emb = 10 #Number of dimension of char embedding vectors\n",
    "n_hidden = 300 #Number of neurons in hidden layer\n",
    "g = torch.Generator().manual_seed(2147843647) #seed for reproducibility\n",
    "\n",
    "C = torch.randn((vocab_size, n_emb), generator= g ) #Indexing embedding, with shape of vocab_size and n_emb\n",
    "\n",
    "#The model, with the implementation of the classes we created. Basically functioning like torch.Linear & torch.BatchNorm layers\n",
    "layers = [\n",
    "    Linear(n_emb*block_size, n_hidden), Tanh(),\n",
    "    Linear(n_hidden,n_hidden),Tanh(),\n",
    "    Linear(n_hidden, n_hidden), Tanh(),\n",
    "    Linear(n_hidden,n_hidden),Tanh(),\n",
    "    Linear(n_hidden, n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad(): #decorator again, to let torch know that we will not be calling backprop on these\n",
    "    layers[-1].weight *=0.1 #apply to last layer to make model less confident\n",
    "    for layer in layers[:-1]:\n",
    "        if isinstance(layer, Linear): #Code below is applied to Linear layers in the layers list\n",
    "            layer.weight *= 5/3 #apply nonlinearity gain to our Linear layers\n",
    "            \n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()] #Number of parameters in our model\n",
    "print(sum(p.nelement() for p in parameters), 'parameters') #num of params printed\n",
    "for p in parameters:\n",
    "    p.requires_grad = True #Set that parameters require gradients, so we can backprop on them\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#Same as before modified to fit new code better\n",
    "step_size = 100000\n",
    "batch_size = 64\n",
    "loss_acq = []\n",
    "\n",
    "for i in range(step_size):\n",
    "    #Minibatch from dataset\n",
    "    ix = torch.randint(0,X_train.shape[0], (batch_size, ),    generator=g) \n",
    "    Xtr, Ytr = X_train[ix], y_train[ix]\n",
    "    \n",
    "    #Forward pass\n",
    "    emb = C[Xtr] #Embedding vector\n",
    "    x = emb.view(emb.shape[0],-1) #Joined embedding to have same number of dimensions as w1 for matrix muliplication\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x,Ytr)\n",
    "    \n",
    "    #Backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad()\n",
    "    for p in parameters:\n",
    "        p.grad =None\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update\n",
    "    lr= 0.1 if i < 50000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    #Tracking stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i:7d}/{step_size:7d}: {loss.item():.4f}')\n",
    "    loss_acq.append(loss.log10().item())\n",
    "    #break\n",
    "        \n",
    "print(loss.item())\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
